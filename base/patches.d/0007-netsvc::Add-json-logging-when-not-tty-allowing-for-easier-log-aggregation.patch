If no tty is detected, the instance switches to json logging
which is easier to work with in log aggregation flows


 odoo/netsvc.py | 22 ++++++++++++++++++++++
 1 file changed, 22 insertions(+)

diff --git a/odoo/netsvc.py b/odoo/netsvc.py
index 326228bf4f9..acdf09351bf 100644
--- a/odoo/netsvc.py
+++ b/odoo/netsvc.py
@@ -9,20 +9,25 @@ import pprint
 import release
 import sys
 import threading
 
 import psycopg2
 
 import odoo
 import sql_db
 import tools
 
+try:
+    from pythonjsonlogger import jsonlogger
+except ImportError:
+    jsonlogger = None
+
 _logger = logging.getLogger(__name__)
 
 def log(logger, level, prefix, msg, depth=None):
     indent=''
     indent_after=' '*len(prefix)
     for line in (prefix + pprint.pformat(msg, depth=depth)).split('\n'):
         logger.log(level, indent+line)
         indent=indent_after
 
 def LocalService(name):
@@ -89,108 +94,125 @@ BOLD_SEQ = "\033[1m"
 COLOR_PATTERN = "%s%s%%s%s" % (COLOR_SEQ, COLOR_SEQ, RESET_SEQ)
 LEVEL_COLOR_MAPPING = {
     logging.DEBUG: (BLUE, DEFAULT),
     logging.INFO: (GREEN, DEFAULT),
     logging.WARNING: (YELLOW, DEFAULT),
     logging.ERROR: (RED, DEFAULT),
     logging.CRITICAL: (WHITE, RED),
 }
 
 class DBFormatter(logging.Formatter):
+    def formatException(self, exc_info):
+        result = super(DBFormatter, self).formatException(exc_info)
+        # Also provide the error's class & module name
+        return '<<<< ' + exc_info[0].__module__ + '.' + exc_info[0].__name__ + ' >>>>\n' + result
     def format(self, record):
         record.pid = os.getpid()
         record.dbname = getattr(threading.currentThread(), 'dbname', '?')
         return logging.Formatter.format(self, record)
 
+if jsonlogger:
+    class JSONFormatter(jsonlogger.JsonFormatter):
+        def formatException(self, exc_info):
+            result = super(JSONFormatter, self).formatException(exc_info)
+            # Also provide the error's class & module name
+            return exc_info[0].__module__ + '.' + exc_info[0].__name__ + ' >>>> ' + result
+        def format(self, record):
+            record.pid = os.getpid()
+            record.dbname = getattr(threading.currentThread(), 'dbname', '?')
+            return jsonlogger.JsonFormatter.format(self, record)
+
 class ColoredFormatter(DBFormatter):
     def format(self, record):
         fg_color, bg_color = LEVEL_COLOR_MAPPING.get(record.levelno, (GREEN, DEFAULT))
         record.levelname = COLOR_PATTERN % (30 + fg_color, 40 + bg_color, record.levelname)
         return DBFormatter.format(self, record)
 
 _logger_init = False
 def init_logger():
     global _logger_init
     if _logger_init:
         return
     _logger_init = True
 
     logging.addLevelName(25, "INFO")
     logging.captureWarnings(True)
 
     from tools.translate import resetlocale
     resetlocale()
 
     # create a format for log messages and dates
     format = '%(asctime)s %(pid)s %(levelname)s %(dbname)s %(name)s: %(message)s'
     # Normal Handler on stderr
     handler = logging.StreamHandler()
 
     if tools.config['syslog']:
         # SysLog Handler
         if os.name == 'nt':
             handler = logging.handlers.NTEventLogHandler("%s %s" % (release.description, release.version))
         elif platform.system() == 'Darwin':
             handler = logging.handlers.SysLogHandler('/var/run/log')
         else:
             handler = logging.handlers.SysLogHandler('/dev/log')
         format = '%s %s' % (release.description, release.version) \
                 + ':%(dbname)s:%(levelname)s:%(name)s:%(message)s'
 
     elif tools.config['logfile']:
         # LogFile Handler
         logf = tools.config['logfile']
         try:
             # We check we have the right location for the log files
             dirname = os.path.dirname(logf)
             if dirname and not os.path.isdir(dirname):
                 os.makedirs(dirname)
             if tools.config['logrotate'] is not False:
                 handler = logging.handlers.TimedRotatingFileHandler(filename=logf, when='D', interval=1, backupCount=30)
             elif os.name == 'posix':
                 handler = logging.handlers.WatchedFileHandler(logf)
             else:
                 handler = logging.FileHandler(logf)
         except Exception:
             sys.stderr.write("ERROR: couldn't create the logfile directory. Logging to the standard output.\n")
 
     # Check that handler.stream has a fileno() method: when running OpenERP
     # behind Apache with mod_wsgi, handler.stream will have type mod_wsgi.Log,
     # which has no fileno() method. (mod_wsgi.Log is what is being bound to
     # sys.stderr when the logging.StreamHandler is being constructed above.)
     def is_a_tty(stream):
         return hasattr(stream, 'fileno') and os.isatty(stream.fileno())
 
     if os.name == 'posix' and isinstance(handler, logging.StreamHandler) and is_a_tty(handler.stream):
         formatter = ColoredFormatter(format)
+    elif jsonlogger:
+        formatter = JSONFormatter(format)
     else:
         formatter = DBFormatter(format)
     handler.setFormatter(formatter)
 
     logging.getLogger().addHandler(handler)
 
     if tools.config['log_db']:
         db_levels = {
             'debug': logging.DEBUG,
             'info': logging.INFO,
             'warning': logging.WARNING,
             'error': logging.ERROR,
             'critical': logging.CRITICAL,
         }
         postgresqlHandler = PostgreSQLHandler()
         postgresqlHandler.setLevel(int(db_levels.get(tools.config['log_db_level'], tools.config['log_db_level'])))
         logging.getLogger().addHandler(postgresqlHandler)
 
     # Configure loggers levels
     pseudo_config = PSEUDOCONFIG_MAPPER.get(tools.config['log_level'], [])
 
     logconfig = tools.config['log_handler']
 
     logging_configurations = DEFAULT_LOG_CONFIGURATION + pseudo_config + logconfig
     for logconfig_item in logging_configurations:
         loggername, level = logconfig_item.split(':')
         level = getattr(logging, level, logging.INFO)
         logger = logging.getLogger(loggername)
         logger.setLevel(level)
 
     for logconfig_item in logging_configurations:
         _logger.debug('logger level set: "%s"', logconfig_item)
